<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  


  <title>AdvBDGen</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">AdvBDGen: Adversarially fortified prompt-specific fuzzy backdoor generator against LLM alignment.</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://pankayaraj.github.io/" target="_blank">Pankayaraj Pathmanathan</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://udarimadhu.github.io/" target="_blank">Udari Madhushani Sehwag</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=MOP6lhkAAAAJ&hl=ro" target="_blank">Michael-Andrei Panaitescu-Liess</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="https://furong-huang.com/" target="_blank">Furong Huang</a><sup>1</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Maryland <sup>1</sup> JP Morgan AI Research <sup>2</sup> </span>
                    <!--<span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>-->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2410.11283" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Arxiv</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://github.com/pankayaraj/AdvBDGen" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                        
                <span class="link-block">
                      <a href="https://x.com/furongh/status/1846999541641297960" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-twitter"></i>
                      </span>
                      <span>Twitter</span>
                    </a>
                  </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/Teaser.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <b>Overview of AdvBDGen</b> :The generator learns to encode complex backdoor triggers into prompts, ensuring prompt-specific adaptability and stealthiness. The strong discriminator detects these triggers to ensure successful trigger installation, while the weak discriminator fails to detect them, preventing reliance on easily identifiable patterns. This adversarial setup refines the triggers to be stealthy, adaptable, and resistant to standard detection methods
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            With the growing adoption of reinforcement learning with human feedback (RLHF) for aligning large language models (LLMs), the risk of backdoor installation during alignment has increased, leading to unintended and harmful behaviors. Existing backdoor triggers are typically limited to fixed word patterns, making them detectable during data cleaning and easily removable post-poisoning. In this work, we explore the use of prompt-specific paraphrases as backdoor triggers, enhancing their stealth and resistance to removal during LLM alignment. We propose AdvBDGen, an adversarially fortified generative fine-tuning framework that automatically generates prompt-specific backdoors that are effective, stealthy, and transferable across models. AdvBDGen employs a generator-discriminator pair, fortified by an adversary, to ensure the installability and stealthiness of backdoors. It enables the crafting and successful installation of complex triggers using as little as 3% of the fine-tuning data. Once installed, these backdoors can jailbreak LLMs during inference, demonstrate improved stability against perturbations compared to traditional constant triggers, and are more challenging to remove. These findings underscore an urgent need for the research community to develop more robust defenses against adversarial backdoor threats in LLM alignment.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

    

    
<section class="hero is-small">
  <div class="hero-body">

    <div style="text-align: center;" class="container">
        <h2 class="title is-3"> Methodology </h2>
        <p>The key idea behind a backdoor attack is to introduce a trigger—such as a patch in an image, a specific word, or a pattern in text—that the targeted model can reliably discern, causing it to exhibit unintended behaviors like generating misaligned responses. We propose a generator-discriminator architecture where the generator encodes the backdoor trigger into the prompt, and the discriminator classifies trigger-encoded prompts from clean ones. Both the generator and discriminator are powered by LLMs. The generator's objective is to produce trigger-encoded prompts that preserve the original prompt’s semantic meaning while remaining detectable by the discriminator LLM. However, a straightforward generator-discriminator setup often leads the generator to insert a constant string into the prompts, effectively reducing the attack to a constant trigger scenario. Examples of this behavior are shown in Table \ref{backdoor_example_1_discriminator}. This outcome arises because the setup lacks incentives for the generator to create complex, varied encodings, ultimately failing to develop sophisticated triggers necessary for stealthier backdoor attacks.To introduce complexity into the encoding process, we propose an enhanced approach using two discriminators: an adversarial weak discriminator and a strong discriminator, alongside the generator. Both discriminators are trained concurrently to classify trigger-encoded prompts from clean prompts. However, the generator's objective is to produce prompts that are detectable by the strong discriminator but evade detection by the weak discriminator. This design compels the generator to create more sophisticated triggers—subtle enough to bypass the weaker discriminator while still identifiable by the stronger one. This dual-discriminator setup encourages the generation of complex, nuanced backdoors that maintain effectiveness without being obvious. The generator and discriminators are trained simultaneously, as illustrated in Figure \ref{fig:weak_strong_loss}, which demonstrates how the differing learning speeds of the strong and weak discriminators drive the generator to develop increasingly complex triggers over time. </p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Teaser.png" alt="MY ALT TEXT" class="center" />
        <h2 class="subtitle has-text-centered">
          <b>Overview</b>
        </h2>
      </div>
      <div style="text-align: center;" class="item">
        <!-- Your image here -->
        <img src="static/images/Weak_Strong.png"  class="center"/>
        <h2 class="subtitle has-text-centered">
          <b>How the strong and weak discriminators contribute to complex trigger generation</b>
        </h2>
      </div>
      
  </div>
</div>
</div>
</section>
<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div style="text-align: center;" class="container">
        <h2 class="title is-3">Backdoor's Effectiveness, Transferrability and Robustness </h2>
        <p>Our proposed triggers—though slightly more challenging to install—are just as effective as constant trigger. Furthermore, they show transferrability to models that were not used as the dsicriminator in the backdoor generatorion. Moreover, once installed, we find it persists even when perturbed within the semantic context in which it was installed. And these variants can be easily generated by simply altering the sampling strategy of the generator.  </p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Efficency.png" alt="MY ALT TEXT" class="center" />
        <h2 class="subtitle has-text-centered">
          <b>Transferrability of the backdoor</b>:n this figure we show how backdoors generated by AdvBDGen are almost as effective as constant tiggers, transferable across equivalent sized models and are capable of modifying styled paraphrases into an installable backoors.
        </h2>
      </div>
      <div style="text-align: center;" class="item">
        <!-- Your image here -->
        <img src="static/images/Robustness_textual_1.png"  class="center"/>
        <h2 class="subtitle has-text-centered">
          <b>Fuzziness of the backdoor (Qualitative)</b>:Table shows the sensitivity of the backdoors to the semantic meaning of the prompt. Here we show that the backdoors are installed by catching on to the semantics of the trigger rather than a constant artifact. Even when the encoded backdoors are replaced by similar semantically consistent triggers the jailbreak occurs successfully. This showcases the ability of our proposed generative adversarial training paradigm in finding meaningful triggers. Here the both the generator and discriminator are Mistral 7B models and the weak generator is a Tinyllama 1B model.
        </h2>
      </div>
      <div style="text-align: center;" class="item">
        <!-- Your image here -->
        <img src="static/images/Robustness_texual_2.png" class="center" />
        <h2 class="subtitle has-text-centered">
         <b>Fuzziness of the backdoor (Qualitative)</b>:Table shows the sensitivity of the backdoors to the semantic meaning of the prompt. Here we show that the backdoors are installed by catching on to the semantics of the trigger rather than a constant artifact. Even when the encoded backdoors are replaced by similar semantically consistent triggers the jailbreak occurs successfully. This showcases the ability of our proposed generative adversarial training paradigm in finding meaningful triggers. Here the both the generator and discriminator are Mistral 7B models and the weak generator is a Tinyllama 1B model.
       </h2>
     </div>
     <div style="text-align: center;" class="item">
      <!-- Your image here -->
      <img src="static/images/Robustness.png" alt="MY ALT TEXT" class="center" />
      <h2 class="subtitle has-text-centered">
        <b>Fuzziness of the backdoor (Quantitative)</b>: Here, we analyze both the existence and the possibility of finding the fuzzy variants of a given backdoor. Here, we measure the uniqueness of the generated prompts as a fraction of the total generated prompts in order to measure the similarity among them.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
    

    

<section class="hero is-small">
  <div class="hero-body">
    <div style="text-align: center;" class="container">
        <h2 class="title is-3"> Resilience against defence </h2>
        <p>While both encoded and constant triggers exhibit similar resilience to pre and post safety training, our results show that encoded triggers are more resistant to trigger removal even in disadvantageous setups.  </p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/Defence_ASR.png" alt="MY ALT TEXT" class="center" />
        <h2 class="subtitle has-text-centered">
          <b>Resilience against trigger Removal (ASR) </b>: In this figure we show the efficacy of the proposed trigger removal method against both the constant trigger and our proposed fuzzy encoded trigger. In this figure, we show an ablation with the possibility of a different number of triggers being identified and used for trigger removal in the case of our proposed fuzzy backdoor. We can see that even when a very large number of triggers are found, it is harder to remove the already installed fuzzy backdoor as opposed to the constant trigger-based backdoor. For consistency, in both the constant trigger and encoded trigger case, we use the model that was poisoned using 5% of the data.
        </h2>
      </div>
      <div style="text-align: center;" class="item">
        <!-- Your image here -->
        <img src="static/images/Defence_PS.png"  class="center"/>
        <h2 class="subtitle has-text-centered">
         <b>Resilience against trigger Removal (PS) </b>: In this figure we show the efficacy of the proposed trigger removal method against both the constant trigger and our proposed fuzzy encoded trigger. In this figure, we show an ablation with the possibility of a different number of triggers being identified and used for trigger removal in the case of our proposed fuzzy backdoor. We can see that even when a very large number of triggers are found, it is harder to remove the already installed fuzzy backdoor as opposed to the constant trigger-based backdoor. For consistency, in both the constant trigger and encoded trigger case, we use the model that was poisoned using 5% of the data.
        </h2>
      </div>
      <div style="text-align: center;" class="item">
        <!-- Your image here -->
        <img src="static/images/Safety_Training.png" class="center" />
        <h2 class="subtitle has-text-centered">
         <b>Safety training</b>: We consider safety training in both the pre and post poisonining setting. We find that both the constant and our proposed encoded backdoor triggers show the same level of resilience to safety training.
       </h2>
     </div>
  </div>
</div>
</div>
</section>

<!--
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>








<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>

    
-->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{pathmanathan2024advbdgenadversariallyfortifiedpromptspecific,
      title={AdvBDGen: Adversarially Fortified Prompt-Specific Fuzzy Backdoor Generator Against LLM Alignment}, 
      author={Pankayaraj Pathmanathan and Udari Madhushani Sehwag and Michael-Andrei Panaitescu-Liess and Furong Huang},
      year={2024},
      eprint={2410.11283},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.11283}, 
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
