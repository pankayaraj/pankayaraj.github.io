<!DOCTYPE HTML>
<html lang="en"><head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-178030306-1"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
        gtag('config', 'UA-178030306-1');
    </script>

    

  <title>Pankayaraj</title>
  
  <meta name="author" content="Pankayaraj">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/web_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Pankayaraj</name>
              </p>
              <p>Currently, I am a research engineer at <a href="https://care-ai.smu.edu.sg/"> CARE AI Lab, Singapore Management University</a> under <a href="http://www.mysmu.edu/faculty/pradeepv/"> Prof. Pradeep Varakantham </a>, where I work on constrained reinforcement learning. From Fall 2022 I will be starting as a PhD student at the <a href= "https://www.cs.umd.edu/">Department of Computer Science, University of Maryland</a>.

              </p>
              <p>
                  
                I have completed my Bachelors of Science in Computer Engineering at <a href="http://www.ce.pdn.ac.lk/"> University of Peradeniya </a>. I have worked at <a href="https://sltc.ac.lk/"> Sri Lanka Technological Campus </a> both as a research Assistant and a research intern under the supervision of <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html"> Prof. D.H.S. Maithripala </a>. I have also remotely collaborated with  <a href="https://flowers.inria.fr/"> Flowers Team, ENSTA Paris </a>, working under the supervision of <a href="https://nataliadiaz.github.io/"> Prof. Natalia Díaz-Rodríguez </a>. During my Undergraduate studies I have won the best final year project research thesis award.
              </p>
              <p style="text-align:center">
                <a href="mailto:p.pankayaraj@gmail.com">Email</a> &nbsp/&nbsp
                <a href="https://punk95.github.io/reports/PankayarajCV.pdf">CV</a> &nbsp/&nbsp
                <!--- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp --->
                <a href="https://scholar.google.com/citations?user=G_gAOpwAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <!--- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp --->
                <a href="https://github.com/punk95">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="https://punk95.github.io/"><img style="width:100%;max-width:100%" alt="profile photo" src="pictures/about.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:0px;width:100%;vertical-align:middle">
                <heading><b><u>I. Research Summary</u></b></heading>
              <p>In general my research interests are on Reinforcement Learning(RL). My past experiences in the field of RL span across continual RL, multi agent RL, bayesian RL, bandits. Currently, I am interested in imitation, constrained RL and explainability in RL. Below you can find my past publications and projects. 
              </p>
            </td>
          </tr>
        </tbody></table>
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <heading><b><u>II. Publications and Pre-Prints</u></b></heading>
        </tbody></table>
        
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <p  style="color:slateblue;font-size:18px" ><b>2021 - 2022: <u><i>Constrained Reinforcement Learning</i></u></b></p>
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/Four_Roooms.png' width="160"></div>
                    <img src='pictures/Four_Roooms.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://github.com/punk95/Hierarchical-constrained-RL">
                        <papertitle>Constrained Reinforcement Learning in Hard Exploration Problems with Hierarchies</papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                        <a href="http://www.mysmu.edu/faculty/pradeepv/">  Pradeep Varakantham </a>,

                      <br>
                                    <em> Under Conference Submission</em>, 2022
                      <br>
                      
                      <a href="https://github.com/punk95/Hierarchical-constrained-RL"> GitHub</a>

                      <p></p>
                      <p>In this work, we propose a method to incorporate and satisfy constraints at every time step in a hierarchical reinforcement learning (HRL) framework. In particular, we propose a way to incorporate backward value functions into an options-based HRL framework. This incorporation depends on the fact that there exists a steady distribution in the HRL framework. To this end under some assumptions, we prove the existence of such a stationary distribution for the markov decision process at every level of the hierarchy. Furthermore, empirically we show the importance of our proposal in terms of efficient exploration as normally the exploration gets curtailed as constraint satisfaction becomes a focal point agent </p>
                </td>   
            </tr>
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <p  style="color:slateblue;font-size:18px" ><b>2020 - 2021: <u><i>Continual Reinforcement Learning</i></u></b></p>
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/cur_cl_rl.PNG' width="160"></div>
                    <img src='pictures/cur_cl_rl.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://github.com/punk95/Continual-Learning-With-Curiosity">
                        <papertitle>Using Curiosity for an Even Representation of Tasks in Continual Offline RL</papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                      <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html">D.H.S Maithripala</a>,
                      <a href="https://fr.linkedin.com/in/elisa-massi-64113310a">Elisa Massi</a>,
                      <a href="https://jrlab.science/">Javier Del Ser</a>,
                      <a href="https://nataliadiaz.github.io/">Natalia Dıaz-Rodrıguez</a>,
                      

                      <br>
                                    <em> Work Under Finalization</em>, 2021
                      <br>

                      
                      <a href="https://github.com/punk95/Continual-Learning-With-Curiosity"> GitHub</a>

                      <p></p>
                      <p>In this work we investigate the means of using curiosity on replay buffers in order to improveofflinemulti-taskcontinual reinforcement learning when tasks, which are defined by the non-stationarity in theenvironment, arenon labeledandnot evenly exposed to the learner in time. In particular, we investigatethe use of curiosity both as atool for the task boundary detectionand as apriority metric when it comesto retaining old transition tuples, which we respectively use to propose two different buffers. Firstly, wepropose the Hybrid Reservoir Buffer with Task Separation(HRBTS) where curiosity was used to detect taskboundaries that are not known due to the task agnostic nature of the problem. Secondly, by using curiosity,as a priority metric when it comes to retaining old transition tuples, a Hybrid Curious Buffer(HCB) wasproposed. </p>
                </td>   
            </tr>
        </tbody></table>
          
        
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <p  style="color:slateblue;font-size:18px" ><b>2020 - 2020: <u><i>Multi Agent Reinforcement Learning</i></u></b></p>
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/marl_1.PNG' width="160"></div>
                    <img src='pictures/marl_1.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://www.researchgate.net/publication/351599797_Temporally_Aware_Multi-Agent_Reinforcement_Learning_in_Sparsely_Connected_Cooprative_Enviornments">
                        <papertitle>Temporally Aware Multi-Agent Reinforcement Learning  in Sparsely Connected Cooperative Environments </papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                      <a href="https://www.linkedin.com/in/yuvini-sumanasekera/?originalSubdomain=lk">Yuvini Sumanasekera</a>,
                      <a href="https://www.linkedin.com/in/chandima-samarasinghe-2235b298/?originalSubdomain=lk">Chandima Samarasinghe</a>,
                      <a href="http://www.ce.pdn.ac.lk/academic-staff/dhammika-elkaduwe/">Dhammika Elkaduwe</a>,
                      <a href="http://www.ce.pdn.ac.lk/upul/">Upul Jayasinghe </a>,
                      <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html">D.H.S Maithripala</a>,
                      
                                           
                      <br>
                                    <em> <b>ESCaPe (Symposium)</b>, Sri Lanka</em>, 2020
                      <br>

                      <a href="https://www.researchgate.net/publication/351599797_Temporally_Aware_Multi-Agent_Reinforcement_Learning_in_Sparsely_Connected_Cooprative_Enviornments">Researchgate</a>
                      /
                      <a href="https://github.com/punk95/Temporal-Attention-Based-MARL"> GitHub</a>

                      <p></p>
                      <p>In this work,  we propose a model which exploitsthe inherent graph-like structure of multi-agent networks to facilitate the learning of more robustbehaviour strategies by capturing the spatial dependencies and temporal dynamics of the underlying graph.</p>
                </td>   
            </tr>
            
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <p  style="color:slateblue;font-size:18px" ><b>2019 - 2020: <u><i>Reinforcement Learning Based Quadcopter Control</i></u></b></p>
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/quad_review.PNG' width="160"></div>
                    <img src='pictures/quad_review.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://www.researchgate.net/publication/352164771_A_Review_on_Reinforcement_Learning_Based_Autonomous_Quadcopter_Control">
                        <papertitle>A Review on Reinforcement Learning Based Autonomous Quadcopter Control </papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                      <a href="https://www.linkedin.com/in/chandima-samarasinghe-2235b298/?originalSubdomain=lk">Chandima Samarasinghe</a>,
                      <a href="https://www.linkedin.com/in/yuvini-sumanasekera/?originalSubdomain=lk">Yuvini Sumanasekera</a>,

                      <br>
                                    <em> Pre-Print</em>
                      <br>

                      <a href="https://www.researchgate.net/publication/352164771_A_Review_on_Reinforcement_Learning_Based_Autonomous_Quadcopter_Control">Researchgate</a>
                      
                     

                      <p></p>
                      <p>In recent years, extensive research has been carriedout  in  the  field  of  autonomous  aerial  vehicle  control,  motivatedby the rapid advancements in Machine Learning (ML). In partic-ular, Reinforcement Learning (RL) has gained immense interestin   developing  control   algorithms.  In   this   work,  we   examinekey  control  problems  related  to  the  operation  of  quadcoptersautonomously  and  analyze  how  past  efforts  have  applied  RLtechniques to approach these problems.</p>
                </td>   
            </tr>
            
        </tbody></table>
        
          
        
        
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            
            <p  style="color:slateblue;font-size:18px" ><b>2019 - 2020: <u><i>Multi Agent Multi Arm Bandit Research</i></u></b></p>
        
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/cdc_1.PNG' width="160"></div>
                    <img src='pictures/cdc_1.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/2003.12968">
                        <papertitle>A Decentralized Policy with Logarithmic Regret for a Class of Multi-Agent Multi-Armed Bandit Problems with Option Unavailability Constraints and Stochastic Communication Protocols </papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                      <a href="https://www.nsf.gov/staff/staff_bio.jsp?lan=jberg&org=CMMI&from_org=CMMI"> J. M. Berg</a>,
                      <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html">D.H.S Maithripala</a>,
                      

                      <br>
                                    <em>59th <b>IEEE Conference on Decision and Control(IEEE CDC)</b>, Jeju Island, Republic of Korea</em>, 2020
                      <br>

                      <a href="https://arxiv.org/abs/2003.12968">arXiv</a>
                      /
                      <a href="https://ieeexplore.ieee.org/document/9304002">IEEE</a>
                      

                      <p></p>
                      <p>This paper considers a multi-armed bandit (MAB) problem in which multiple mobile agents receive rewards by sampling from a collection of spatially dispersed bandits. The goal is to formulate a decentralized policy for each agent, in order to maximize the total cumulative reward over all agents, subject to option availability and inter-agent communication constraints.</p>
                </td>   
            </tr>
            
            
           <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/ecc_1.PNG' width="160"></div>
                    <img src='pictures/ecc_1.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/abs/1910.02635">
                        <papertitle>A Decentralized Communication Policy for Multi Agent Multi Armed Bandit Problems </papertitle>
                      </a>
                      <br>
                      
                      <strong>Pankayaraj</strong>,
                      <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html">D.H.S Maithripala</a>,
                      

                      <br>
                                    <em> <b>European Control Conference(ECC)</b>, Saint Petersburg, Russia</em>, 2020
                      <br>

                      <a href="https://arxiv.org/abs/1910.02635">arXiv</a>
                      /
                      <a href="https://ieeexplore.ieee.org/document/9143811">IEEE</a>
                      /
                      <a href="https://github.com/punk95/MAMAB_ECC_20"> GitHub</a>

                      <p></p>
                      <p>This paper proposes a novel policy for a group of agents to, individually as well as collectively, solve a multi armed bandit (MAB) problem. The policy relies solely on the information that an agent has obtained through sampling of the options on its own and through communication with neighbors.</p>
                </td>   
            </tr>
        </tbody></table>
          
          
          
        
         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <p  style="color:slateblue;font-size:18px" ><b>2018 - 2019: <u><i>Sleep Apnea Detection</i></u></b></p>
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/sleep_apnea.png' width="160"></div>
                    <img src='pictures/sleep_apnea.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://arxiv.org/pdf/1910.04725.pdf">
                        <papertitle>Non-contact Infant Sleep Apnea Detection</papertitle>
                      </a>
                      <br>
                      <a href="https://gihan.me/">Gihan Jayatilaka</a>,
                      <a href="https://harshana95.github.io/">Harshana Weligampola</a>,
                      <a href="https://suren3141.github.io/">Suren Sritharan</a>,
                      <strong>Pankayaraj</strong>,
                      <a href="http://www.ce.pdn.ac.lk/academic-staff/roshan-g-ragel/">Roshan Ragel</a>,
                      <a href="http://www.ce.pdn.ac.lk/academic-staff/isuru-nawinne/">Isuru Nawinne</a>,

                      <br>
                                    <em><b>ICIIS</b>, Sri Lanka</em>, 2019
                      <br>

                      <a href="https://arxiv.org/pdf/1910.04725.pdf">arXiv</a>
                      /
                      <a href="https://ieeexplore.ieee.org/document/9063269">IEEE</a>
                      /
                      <a href="https://github.com/punk95/Sleep_Apnea_Detection-1"> GitHub</a>

                      <p></p>
                      <p>We propose a non invasive solution for this problem based on video processing. The infant is observed by a video camera which is connected to a single board computer (Raspberry pi) which analyzes the video feed to diagnose breathing anomalies. The camera is turned to a proper orientation for the observation using a robotic arm.</p>
                </td>   
            </tr>
        </tbody></table> 
          
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
                <heading><b><u>III. Academic Volunteering</u></b></heading>
            </td>
          </tr>
        </tbody></table>
          
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="pictures/review/journal_pic.PNG"></td>
            <td width="75%" valign="center">
              <a href="https://publons.com/researcher/3858300/pankayaraj-pathmanathan/">Peer Reviewer : Journal IEEE Transactions on Communications</a> [Impact Factor: 5.69(2018), Done during the undergraduate period]    
            </td>
          </tr>		
					
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
                <heading><b><u>IV. Projects</u></b></heading>
            </td>
          </tr>
        </tbody></table>
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/airsim.png' width="160"></div>
                    <img src='pictures/undergraduate/airsim.png' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/Quadcopter_control_RL.pdf">
                        <papertitle>RL based Quadcopter Control</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/Quadcopter_control_RL.pdf">Report</a>

                      <p></p>
                      <p>In recent years, extensive research has been carried out in the field of autonomous aerial vehicle control, motivated by the rapid advancements in Machine Learning (ML). In particular, Reinforcement Learning (RL) has gained immense interest in developing control algorithms given its ability to learn useful behavior by dynamically interacting with the environment, without the need for an explicit teacher. In this work, we examine the use of RL methods on vision-based quadcopter control in both single-agent and multi-agent simulated environments. Specifically, the DQN algorithm was investigated in the single-agent setting and the MADDPG algorithm in the multi-agent setting. The control task in each of these settings was to navigate through the environment by avoiding obstacles to reach the specified goals. Thus, each of the aforementioned algorithms were evaluated on their ability to perform this control task.</p>
                </td>   
            </tr>
            
            
            <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/MARL_S.PNG' width="160"></div>
                    <img src='pictures/undergraduate/MARL_S.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/MARL_Sparse.pdf">
                        <papertitle>
Multi Agent Reinformcent Learning with Sparse Communication</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/MARL_Sparse.pdf">Report</a>
                      \
                     <a href="https://github.com/punk95/Temporal-Attention-Based-MARL"> GitHub</a>

                      <p></p>
                      <p>In recent years, the consensus among adaptive agents within multi-agent systems (MAS) has been an emerging area of research in the field of autonomous control. Reinforcement Learning (RL) has gained immense interest in this line of work as it aims to learn optimal cooperative policies through trial and error by dynamically interacting with the environment. However, in practice, connectivity within the multi-agent network may be sparse and the agents are often subjected to partial observability. This can result in the learning of sub-optimal policies. In this work, we consider the problem of learning optimal policies in cooperative multi-agent environments in the face of partial observability and sparse connectivity. The proposed model exploits the inherent graph-like structure of multi-agent systems. Graph Neural Networks (GNNs) are utilized to extract spatial dependencies and temporal dynamics of the underlying graph. Such spatio-temporal information is exploited to generate better state representations so as to facilitate the learning of more robust policies. This model builds on the previously explored spatial modelling in MARL.</p>
                </td>   
            </tr>
            
        
          
        <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/recommendation_system.PNG' width="160"></div>
                    <img src='pictures/undergraduate/recommendation_system.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/Recommendation_using_Bayesian_RL.pdf">
                        <papertitle>Bayesian RL based Recommendation System</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/Recommendation_using_Bayesian_RL.pdf">Report</a>
                      \
                     <a href="https://github.com/punk95/sitnshop/tree/master/GPSARSA"> GitHub</a>

                      <p></p>
                      <p>When it comes to user customization it is essential to capture users preferences in an optimal manner so that the user can be served based on his past preferences. The concept behind this work is to formulate an a methodology for an online advertising shop to customize it’s advertisement presentation using the existing algorithms in the literature. The task of the algorithm is to find the next shop to suggest for the user on his time line based on his past preferences. Users preferences will be captured by the ratings he give for a shop when it is shown in his time line and by the fact weather he marks some shop as visited. Most part of the final suggested algorithm follows the 2003 paper named Bayes Meets Bellman: The Gaussian Process Approach to Temporal Difference Learning</p>
                </td>   
        </tr>
            
            
        <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/bayesian_optimization.PNG' width="160"></div>
                    <img src='pictures/undergraduate/bayesian_optimization.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/Bayseian_optimization.pdf">
                        <papertitle>Python based Bayesian Optimization library</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/Bayseian_optimization.pdf">Report</a>
                      \
                      <a href="https://github.com/punk95/Multi-Arm-Bandit-Library"> GitHub</a>
                      \
                      <a href="https://pypi.python.org/pypi/mabandit/1.3"> PyPi </a>

                      <p></p>
                      <p>In probability theory multi arm bandit problem or N-arm bandit problem is a problem in which a gambler at a row machine have to choose which machine to play and how many time to play it given a limited number of turns to choose. When chosen a machine would give a particular amount of reward which is either deterministic or probabilistic. Thus to accumulate an optimal amount of reward the gambler should choose a an optimal solution without knowing the reward structure behind the machine.
                      As the problem moved away from the discrete arms got extended as a continuous variable with a K dimension the problem got extended as continuous bandit problem. Since the no of bandits became infinite to reduce the complexity the problem was formulated with deterministic rewards where the rewards of each arm were considered as a correlated function. As the scope of these problems narrowed down to the bayesian thinking they were named as bayesian optimization. They can be considered as a problem where we are supposed to optimize a function with certain bounds with as few samples as possible.In this work we provide a python based library for the above mentioned bayesian optimization problem</p>
                </td>   
        </tr>
            
       
            
        <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/sitnshop.PNG' width="160"></div>
                    <img src='pictures/undergraduate/sitnshop.PNG' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/SitNShop.pdf">
                        <papertitle>SitNShop</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/SitNShop.pdf">Report</a>
                      \
                     <a href="https://github.com/punk95/sitnshop"> GitHub</a>

                      
                      <p>The concept behind this project is to design and implement a web page to connect the local customers with the local shop owners by building a platform for advertisements. This project is build on the basis of providing an interactive interface for both users and shop owners with the ability to convey the information about them as much as possible while focusing also on the development of a capable algorithm to capture the preference of the customer dynamically.</p>
                </td>   
        </tr>
            
        
        <tr onmouseout="mip360_stop()" onmouseover="mip360_start()">
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <div class="one">
                    <div class="two" id='nerfactor_image'>
                      <img src='pictures/undergraduate/sleep_apnea.jpg' width="160"></div>
                    <img src='pictures/undergraduate/sleep_apnea.jpg' width="160">
                  </div>
                  <script type="text/javascript">
                    function nerfactor_start() {
                      document.getElementById('nerfactor_image').style.opacity = "1";
                    }

                    function nerfactor_stop() {
                      document.getElementById('nerfactor_image').style.opacity = "0";
                    }
                    nerfactor_stop()
                  </script>
                </td>

                <td style="padding:20px;width:75%;vertical-align:middle">
                      <a href="https://punk95.github.io/reports/undergraduate/Seep_apnea_detection_report.pdf">
                        <papertitle>Non Contact Sleep Apnea Detection</papertitle>
                      </a>
                      <br>
                    
                      <a href="https://punk95.github.io/reports/undergraduate/Seep_apnea_detection_report.pdf">Report</a>
                      \
                     <a href="https://github.com/punk95/Sleep_Apnea_Detection-1"> GitHub</a>

                      <p></p>
                      <p>Sleep Apnea is a serious disorder caused by the interruption of breathing during sleep. This can cause the people to stop breathing for several time even hundreds if not treated properly. It can affect people of any age. But when the babies are affected with the condition they tend to not get up and keep on sleeping which may risk their lives. We propose a non invasive solution for this problem based on video processing. The infant is observed by a video camera which is connected to a single board computer (Raspberry pi) which analyzes the video feed to diagnose breathing anomalies. The camera is turned to a proper orientation for the observation using a robotic arm.</p>
                </td>   
        </tr>
            
        </tbody></table>
        
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <heading><b><u>V. References</u></b> </heading>
          <tr>
            <td style="padding:00px">
              
              <p>
              <a 
              href= http://www.mysmu.edu/faculty/pradeepv/ >1. Prof. Pradeep Varakantham</a> <br>
              Lee Kuan Yew Fellow <br>
              Professor of Computer Science <br>
              School of Computing and Information Systems, Singapore Management University<br>
              <a href="mailto:pradeepv@smu.edu.sg ">pradeepv@smu.edu.sg</a>
              </p> 
                
                
              <p>
              <a href="https://eng.pdn.ac.lk/pages/departmentHome/ME/otherpages/staff/Dr%20Maithripala.html">2. Dr. D.H.S Maithripala </a> <br>
              Senior Lecturer <br>
              Department of Mechanical Engineering, University of Peradeniya, Sri Lanka. <br>
              <a href="mailto:smaithri@pdn.ac.lk">smaithri@pdn.ac.lk</a>
                
              </p>
                
            
            
              <p>
              <a href="https://nataliadiaz.github.io/">3. Prof. Natalia Díaz-Rodríguez </a> <br>
              Assistant Professor <br>
              Department of Computer Science and Artificial Intelligence, University of Granada, Spain. <br>
              <a href="mailto:nataliadiaz@ugr.es">nataliadiaz@ugr.es</a>
                
              </p>
            
              <p>
              <a href="http://eng.pdn.ac.lk/old/engmath/staff/Dr-rathnamali.html">4. Dr. G. W. R. M. R. Palamakumbura </a> <br>
              Senior Lecturer <br>
              Department of Department of Engineering Mathematics, University of Peradeniya, Sri Lanka. <br>
              <a href="mailto:rpalam@pdn.ac.lk">rpalam@pdn.ac.lk</a>
                
              </p>
                
              <p>
              <a href="http://www.ce.pdn.ac.lk/academic-staff/isuru-nawinne/">5. Dr. Isuru Nawinne </a> <br>
              Senior Lecturer <br>
              Department of Computer Engineering, University of Peradeniya, Sri Lanka. <br>
              <a href="mailto:isurunawinne@eng.pdn.ac.lk">isurunawinne@eng.pdn.ac.lk</a>
                
              </p>
              
            </td>
          </tr>
        </tbody></table>
          
          
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:80px">
              <br>
              <p style="text-align:right;font-size:small;">
              Credits: <a href="https://jonbarron.info/"> <b>Jon Barron</b></a> <br>
              Last Updated: <b>28-Dec-2021</b>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
